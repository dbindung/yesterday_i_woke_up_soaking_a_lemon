{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tensor(tensor, title='Tensor Visualization'):\n",
    "    \"\"\"\n",
    "    Визуализирует PyTorch тензор с помощью Matplotlib.\n",
    "\n",
    "    Параметры:\n",
    "    - tensor (torch.Tensor): Тензор изображения. Должен быть размерностью (C, H, W) или (H, W) для градаций серого.\n",
    "    - title (str): Заголовок графика.\n",
    "    \"\"\"\n",
    "    # Проверяем, что тензор находится на GPU и переносим его на CPU\n",
    "    tensor = tensor.cpu()\n",
    "\n",
    "    # Если тензор имеет 3 канала (например, RGB), переведём его в numpy массив и изменим порядок осей\n",
    "    if tensor.dim() == 3 and tensor.size(0) == 3:\n",
    "        img = tensor.permute(1, 2, 0).numpy()\n",
    "    elif tensor.dim() == 3:\n",
    "        # Если тензор имеет больше одного канала (например, выходной слой модели), отображаем только первый канал\n",
    "        img = tensor[0].numpy()\n",
    "    elif tensor.dim() == 2:\n",
    "        # Если тензор имеет только 2D (градации серого)\n",
    "        img = tensor.numpy()\n",
    "    else:\n",
    "        raise ValueError(\"Тензор должен быть размерности (C, H, W) или (H, W).\")\n",
    "\n",
    "    # Проверяем и нормализуем изображение для корректного отображения\n",
    "    if img.min() < 0 or img.max() > 1:\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "    # Отображаем изображение\n",
    "    plt.imshow(img, cmap='gray' if img.ndim == 2 else None)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')  # Не показывать оси\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_concat(down_tensor, up_tensor):\n",
    "    crop_height = (up_tensor.size(2) - down_tensor.size(2)) // 2\n",
    "    crop_width = (up_tensor.size(3) - down_tensor.size(3)) // 2\n",
    "    \n",
    "    up_tensor_cropped = up_tensor[:, :, crop_height:crop_height + down_tensor.size(2), crop_width:crop_width + down_tensor.size(3)]\n",
    "    \n",
    "    return torch.cat((up_tensor_cropped, down_tensor), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNetConvLayer, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # encoder (downsampling)\n",
    "        # Each enc_conv/dec_conv block should look like this:\n",
    "        # nn.Sequential(\n",
    "        #     nn.Conv2d(...),\n",
    "        #     ... (2 or 3 conv layers with relu and batchnorm),\n",
    "        # )\n",
    "        self.enc_conv0 = UNetConvLayer(3, 64)\n",
    "        self.pool0 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "        self.enc_conv1 = UNetConvLayer(64, 128)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "        self.enc_conv2 = UNetConvLayer(128, 256)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "        self.enc_conv3 = UNetConvLayer(256, 512)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "\n",
    "        # bottleneck\n",
    "        self.bottleneck_conv = UNetConvLayer(512, 1024)\n",
    "\n",
    "        # decoder (upsampling)\n",
    "        self.upsample0 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec_conv0 = UNetConvLayer(1024, 512)\n",
    "        self.upsample1 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec_conv1 = UNetConvLayer(512, 256)\n",
    "        self.upsample2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec_conv2 = UNetConvLayer(256, 128)\n",
    "        self.upsample3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec_conv3 = UNetConvLayer(128, 64)\n",
    "        self.final_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e0 = self.enc_conv0(x)\n",
    "        e1, idx1 = self.pool0(e0)\n",
    "        e1 = self.enc_conv1(e1)\n",
    "        e2, idx2 = self.pool1(e1)\n",
    "        e2 = self.enc_conv2(e2)\n",
    "        e3, idx3 = self.pool2(e2)\n",
    "        e3 = self.enc_conv3(e3)\n",
    "        e4, idx4 = self.pool3(e3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck_conv(e4)\n",
    "        # print(b.size())\n",
    "\n",
    "\n",
    "        # decoder\n",
    "        d0 = self.upsample0(b)\n",
    "        d0 = crop_and_concat(d0, e3)  # concatenate along the channel axis\n",
    "        d0 = self.dec_conv0(d0)\n",
    "\n",
    "        d1 = self.upsample1(d0)\n",
    "        d1 = crop_and_concat(d1, e2)  # concatenate along the channel axis\n",
    "        d1 = self.dec_conv1(d1)\n",
    "\n",
    "        d2 = self.upsample2(d1)\n",
    "        d2 = crop_and_concat(d2, e1)  # concatenate along the channel axis\n",
    "        d2 = self.dec_conv2(d2)\n",
    "\n",
    "        d3 = self.upsample3(d2)\n",
    "        d3 = crop_and_concat(d3, e0)  # concatenate along the channel axis\n",
    "        d3 = self.dec_conv3(d3)\n",
    "\n",
    "        d3 = self.final_conv(d3)\n",
    "        return d3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
