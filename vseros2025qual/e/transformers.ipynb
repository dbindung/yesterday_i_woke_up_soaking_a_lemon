{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f14a9286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "604560c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4e536e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AppDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len, label2id, is_train=True):\n",
    "        self.texts = (df['app_name'] + ' [SEP] ' + \n",
    "                      df['shortDescription'].fillna('') + ' [SEP] ' +\n",
    "                      df['full_description'].fillna('')).tolist()\n",
    "        self.is_train = is_train\n",
    "        if self.is_train:\n",
    "            self.labels = df['labels_str'].apply(\n",
    "                lambda labs: [label2id[l] for l in labs if l in label2id]\n",
    "            ).tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.label2id = label2id\n",
    "        self.num_classes = len(label2id)\n",
    "        self.extra_features = df[['app_name_length', 'full_description_length', 'shortDescription_length',\n",
    "       'app_name_sumbols_per_word', 'full_description_sumbols_per_word',\n",
    "       'shortDescription_sumbols_per_word']].values.astype('float32')\n",
    "\n",
    "\n",
    "    def __len__(self): return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        if self.is_train:\n",
    "            target = torch.zeros(self.num_classes, dtype=torch.float)\n",
    "            for l in self.labels[idx]:\n",
    "                target[l] = 1\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": target if self.is_train else np.zeros(45),\n",
    "            \"extra_feats\": torch.tensor(self.extra_features[idx], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5396ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelClassifier(nn.Module):\n",
    "    def __init__(self, model_name, num_labels, extra_dim=6):\n",
    "        super().__init__()\n",
    "        self.backbone = AutoModel.from_pretrained(model_name)\n",
    "        hidden_size = self.backbone.config.hidden_size\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        # добавляем вход для доп. фичей\n",
    "        self.fc = nn.Linear(hidden_size + extra_dim, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, extra_feats):\n",
    "        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls = outputs.last_hidden_state[:, 0, :]  # [CLS]\n",
    "        concat = torch.cat([cls, extra_feats], dim=1)\n",
    "        logits = self.fc(self.dropout(concat))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4f5dc9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    for batch in tqdm(loader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask, batch[\"extra_feats\"].to(device))\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f1239205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hitrate_at_3(preds, labels):\n",
    "    \"\"\" preds, labels: numpy arrays \"\"\"\n",
    "    hits = 0\n",
    "    for p, l in zip(preds, labels):\n",
    "        true_idx = np.where(l == 1)[0]\n",
    "        top3 = p.argsort()[-3:][::-1]\n",
    "        if len(set(true_idx) & set(top3)) > 0:\n",
    "            hits += 1\n",
    "    return hits / len(labels)\n",
    "\n",
    "\n",
    "def eval_epoch(model, loader, device):\n",
    "    model.eval()\n",
    "    preds_all, labels_all = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].cpu().numpy()\n",
    "            logits = model(input_ids, attention_mask, batch[\"extra_feats\"].to(device))\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            preds_all.append(probs)\n",
    "            labels_all.append(labels)\n",
    "    preds_all = np.vstack(preds_all)\n",
    "    labels_all = np.vstack(labels_all)\n",
    "    return hitrate_at_3(preds_all, labels_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3e43126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    preds_all = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            logits = model(input_ids, attention_mask, batch[\"extra_feats\"].to(device))\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            preds_all.append(probs)\n",
    "    preds_all = np.vstack(preds_all)\n",
    "    return preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "775e0a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_name</th>\n",
       "      <th>full_description</th>\n",
       "      <th>shortDescription</th>\n",
       "      <th>labels_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Матрона Московская.</td>\n",
       "      <td>Хочешь знать что будет? Загляни в будущие. Мат...</td>\n",
       "      <td>Узнать будущее. Предсказания . Магия волшебног...</td>\n",
       "      <td>lifestyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run and Jump - \"Бесконечный раннер\"</td>\n",
       "      <td>Run and Jump это новая увлекательная Аркада - ...</td>\n",
       "      <td>Платформенная Аркада - Раннер с захватывающим ...</td>\n",
       "      <td>action|arcade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ghost Maze</td>\n",
       "      <td>Играя за приведение, собирай необходимые комби...</td>\n",
       "      <td>Игра-головоломка. Попробуй найти выход из лаби...</td>\n",
       "      <td>arcade|puzzle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LabTools Mobile: ЛАБОРАТОРНЫЕ ПРИБОРЫ</td>\n",
       "      <td>AR-приложение «LabTools Mobile: Лабораторные п...</td>\n",
       "      <td>AR-приложение которое предназначено для изучен...</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mario Anime Coloring</td>\n",
       "      <td>\\nРаскрасьте своих любимых персонажей из mario...</td>\n",
       "      <td>Раскрасьте своих любимых персонажей из mario я...</td>\n",
       "      <td>children|family</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                app_name  \\\n",
       "0                    Матрона Московская.   \n",
       "1    Run and Jump - \"Бесконечный раннер\"   \n",
       "2                             Ghost Maze   \n",
       "3  LabTools Mobile: ЛАБОРАТОРНЫЕ ПРИБОРЫ   \n",
       "4                   Mario Anime Coloring   \n",
       "\n",
       "                                    full_description  \\\n",
       "0  Хочешь знать что будет? Загляни в будущие. Мат...   \n",
       "1  Run and Jump это новая увлекательная Аркада - ...   \n",
       "2  Играя за приведение, собирай необходимые комби...   \n",
       "3  AR-приложение «LabTools Mobile: Лабораторные п...   \n",
       "4  \\nРаскрасьте своих любимых персонажей из mario...   \n",
       "\n",
       "                                    shortDescription       labels_str  \n",
       "0  Узнать будущее. Предсказания . Магия волшебног...        lifestyle  \n",
       "1  Платформенная Аркада - Раннер с захватывающим ...    action|arcade  \n",
       "2  Игра-головоломка. Попробуй найти выход из лаби...    arcade|puzzle  \n",
       "3  AR-приложение которое предназначено для изучен...        education  \n",
       "4  Раскрасьте своих любимых персонажей из mario я...  children|family  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.tsv', sep='\\t')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "82a53642",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['labels_str'] = train['labels_str'].apply(lambda x: x.split('|'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b58f88",
   "metadata": {},
   "source": [
    "# фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "70f9661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[~train['full_description'].apply(str).str.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b804bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['app_name_length'] = train['app_name'].apply(lambda x: len(x.split(' ')))\n",
    "train['full_description_length'] = train['full_description'].apply(lambda x: len(x.split(' ')))\n",
    "train['shortDescription_length'] = train['shortDescription'].apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "train['app_name_length_in_symbols'] = train['app_name'].apply(len)\n",
    "train['full_description_length_in_symbols'] = train['full_description'].apply(len)\n",
    "train['shortDescription_length_in_symbols'] = train['shortDescription'].apply(lambda x: len(str(x)))\n",
    "\n",
    "train['app_name_sumbols_per_word'] = train['app_name_length_in_symbols'] // train['app_name_length']\n",
    "train['full_description_sumbols_per_word'] = train['full_description_length_in_symbols'] // train['full_description_length']\n",
    "train['shortDescription_sumbols_per_word'] = train['shortDescription_length_in_symbols'] // train['shortDescription_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5af9004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['app_name_length_in_symbols', 'full_description_length_in_symbols', 'shortDescription_length_in_symbols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d82a790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f9580df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "14cbf620",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ai-forever/ruRoberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "15af99d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = sorted(set(l for labs in train.labels_str for l in labs))\n",
    "label2id = {label: i for i, label in enumerate(all_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5b19476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_test_split(train, test_size=0.2, random_state=185)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cefb3597",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.copy()\n",
    "X_val = X_val.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "216fc4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_norm = [\n",
    "    'app_name_length', 'full_description_length', 'shortDescription_length',\n",
    "    'app_name_sumbols_per_word', 'full_description_sumbols_per_word',\n",
    "    'shortDescription_sumbols_per_word'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6aefe973",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train.loc[:, features_to_norm] = scaler.fit_transform(X_train[features_to_norm])\n",
    "\n",
    "X_val.loc[:, features_to_norm] = scaler.transform(X_val[features_to_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a3451101",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = AppDataset(X_train, tokenizer, 300, label2id)\n",
    "val_set = AppDataset(X_val, tokenizer, 300, label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bf6aeb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "92246a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ai-forever/ruRoberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/user/.local/lib/python3.8/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultiLabelClassifier(model_name, num_labels=len(label2id)).to(device)\n",
    "# for param in model.backbone.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_training_steps = len(train_loader) * 5  # 3 эпохи\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=int(0.1 * num_training_steps)\n",
    ", num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "25c650ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a9b374d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(\"checkpoints\")\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "best_h3 = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "52001340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(save_dir / \"model_epoch3.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d8a47dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2674/2674 [39:21<00:00,  1.13it/s]\n",
      "100%|██████████| 669/669 [03:13<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train loss: 0.1021 | Val H@3: 0.9095\n",
      "✓ Saved new best model (H@3=0.9095)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2674/2674 [39:26<00:00,  1.13it/s]\n",
      "100%|██████████| 669/669 [03:14<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 | Train loss: 0.0445 | Val H@3: 0.9242\n",
      "✓ Saved new best model (H@3=0.9242)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2674/2674 [39:34<00:00,  1.13it/s]\n",
      "100%|██████████| 669/669 [03:22<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 | Train loss: 0.0388 | Val H@3: 0.9279\n",
      "✓ Saved new best model (H@3=0.9279)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2674/2674 [39:33<00:00,  1.13it/s]\n",
      "100%|██████████| 669/669 [03:18<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 | Train loss: 0.0331 | Val H@3: 0.9311\n",
      "✓ Saved new best model (H@3=0.9311)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2674/2674 [39:26<00:00,  1.13it/s]\n",
      "100%|██████████| 669/669 [03:12<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 | Train loss: 0.0288 | Val H@3: 0.9304\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs): \n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    val_h3 = eval_epoch(model, val_loader, device)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train loss: {train_loss:.4f} | Val H@3: {val_h3:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), save_dir / f\"model_epoch{epoch+1}.pt\")\n",
    "\n",
    "    if val_h3 > best_h3:\n",
    "        best_h3 = val_h3\n",
    "        torch.save(model.state_dict(), save_dir / \"best_model.pt\")\n",
    "        print(f\"✓ Saved new best model (H@3={best_h3:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c0cb3aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(save_dir / \"best_model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb71e34",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "94e76225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_name</th>\n",
       "      <th>full_description</th>\n",
       "      <th>shortDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lemon clicker</td>\n",
       "      <td>Lemon clicker простая игра в казуальном жанре ...</td>\n",
       "      <td>Это игра типа: кликер в котором надо кликать з...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Memo Английский язык</td>\n",
       "      <td>Приложение для изучения английского языка на о...</td>\n",
       "      <td>Приложение для изучения английского языка на о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Slave Man Rescue</td>\n",
       "      <td>Посреди густого леса живут коренные жители это...</td>\n",
       "      <td>Игра-побег: помогите похищенному пленнику сбеж...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taking Care of Granny</td>\n",
       "      <td>Дедушки и бабушки - лучшие спутники в нашем юн...</td>\n",
       "      <td>Увлекательная игра в которой надо помочь одино...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Escape From Classic Room</td>\n",
       "      <td>Escape from Classic Room - это игра-головоломк...</td>\n",
       "      <td>Игра-головоломка, в которой вам нужно найти вы...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   app_name  \\\n",
       "0             Lemon clicker   \n",
       "1      Memo Английский язык   \n",
       "2          Slave Man Rescue   \n",
       "3     Taking Care of Granny   \n",
       "4  Escape From Classic Room   \n",
       "\n",
       "                                    full_description  \\\n",
       "0  Lemon clicker простая игра в казуальном жанре ...   \n",
       "1  Приложение для изучения английского языка на о...   \n",
       "2  Посреди густого леса живут коренные жители это...   \n",
       "3  Дедушки и бабушки - лучшие спутники в нашем юн...   \n",
       "4  Escape from Classic Room - это игра-головоломк...   \n",
       "\n",
       "                                    shortDescription  \n",
       "0  Это игра типа: кликер в котором надо кликать з...  \n",
       "1  Приложение для изучения английского языка на о...  \n",
       "2  Игра-побег: помогите похищенному пленнику сбеж...  \n",
       "3  Увлекательная игра в которой надо помочь одино...  \n",
       "4  Игра-головоломка, в которой вам нужно найти вы...  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('data/test.tsv', sep='\\t')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8da8601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['app_name_length'] = test['app_name'].apply(lambda x: len(x.split(' ')))\n",
    "test['full_description_length'] = test['full_description'].apply(lambda x: len(x.split(' ')))\n",
    "test['shortDescription_length'] = test['shortDescription'].apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "test['app_name_length_in_symbols'] = test['app_name'].apply(len)\n",
    "test['full_description_length_in_symbols'] = test['full_description'].apply(len)\n",
    "test['shortDescription_length_in_symbols'] = test['shortDescription'].apply(lambda x: len(str(x)))\n",
    "\n",
    "test['app_name_sumbols_per_word'] = test['app_name_length_in_symbols'] // test['app_name_length']\n",
    "test['full_description_sumbols_per_word'] = test['full_description_length_in_symbols'] // test['full_description_length']\n",
    "test['shortDescription_sumbols_per_word'] = test['shortDescription_length_in_symbols'] // test['shortDescription_length']\n",
    "\n",
    "test = test.drop(columns=['app_name_length_in_symbols', 'full_description_length_in_symbols', 'shortDescription_length_in_symbols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8bbaab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[features_to_norm] = scaler.transform(test[features_to_norm] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "32f4ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = AppDataset(test, tokenizer, 300, label2id, is_train=False)\n",
    "test_loader = DataLoader(test_set, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f53fa980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 941/941 [04:32<00:00,  3.45it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = predict(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c80f7193",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('rubert-base-cased.probs.npy', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "39efd8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_preds = []\n",
    "for row in preds:\n",
    "    top3 = np.argsort(row)[-3:][::-1]\n",
    "    top3_preds.append(top3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5a923705",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label = {l: i for i, l in label2id.items()}\n",
    "\n",
    "pred_labels = []\n",
    "for top3 in top3_preds:\n",
    "    labels = [idx2label[i] for i in top3]\n",
    "    pred_labels.append(\"|\".join(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9eb51a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"app_name\": test[\"app_name\"],\n",
    "    \"labels_str\": pred_labels\n",
    "})\n",
    "\n",
    "submission.to_csv(\"sub13.tsv\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
