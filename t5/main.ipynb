{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: AI is widely used in a variety of fields, from medicine and finance to automotive and entertainment. key areas of AI include machine learning, deep learning, and neural networks. this process involves training a model on large amounts of data so it can make predictions.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"t5-small\"  # Можно выбрать t5-base или t5-large для более крупных моделей\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Текст, который мы будем обрабатывать\n",
    "text = \"\"\"\n",
    "Artificial intelligence (AI) is a field of computer science that deals with creating machines and programs that can perform tasks that require human intelligence, such as perception, pattern recognition, decision making, and learning. AI is widely used in\n",
    "a variety of fields, from medicine and finance to automotive and entertainment. Key areas of AI include machine learning,\n",
    "deep learning, and neural networks, which allow computers to \"learn\" from data and adapt to new situations.\n",
    "\n",
    "Machine learning is a subset of AI that allows systems to learn from examples, without being explicitly programmed. This process involves\n",
    "training a model on large amounts of data so that it can make predictions or classify new data. Deep learning, on the other hand,\n",
    "is a more sophisticated form of machine learning that uses multi-layered neural networks to process large amounts of data and extract complex\n",
    "dependencies and patterns.\n",
    "\n",
    "Neural networks are inspired by biological neurons in the human brain and are an important tool in the field of AI. They can be used to solve problems such as speech recognition, natural language processing, computer vision, and more. Neural networks learn through a process called backpropagation, which helps the model improve its predictions.\n",
    "\n",
    "As AI technologies advance, more and more companies are starting to implement it in their operations to optimize business processes, improve customer service, and develop new products. At the same time, the use of AI raises a number of ethical issues, such as data privacy, the unpredictability of machine behavior, and its impact on the labor market. In the future, AI will continue to evolve and will likely play an increasingly important role in various aspects of our lives.\n",
    "\"\"\"\n",
    "\n",
    "# Подготовка текста для модели\n",
    "input_text = \"summarize: \" + text  # Для задачи суммаризации добавляем префикс \"summarize:\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "# Генерация ответа\n",
    "outputs = model.generate(inputs[\"input_ids\"], max_length=150, num_beams=4, early_stopping=True)\n",
    "\n",
    "# Декодирование и вывод результата\n",
    "summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transformers are a deep learning model architecture that has achieved great success in various natural language processing tasks. the attention mechanism allows the model to focus on different parts of the input when making predictions.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b56865a6a7d4bd79023f4b9f665cc45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--t5-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc43515986e94b78a287fe0bc5d5699d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2ea51768954c07aed746e0403565e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76155e39fbc24442a0141a534a463ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2329bb23f6943c68d0ecc7354f0325f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: рансормер — то аритектура модели луокоо оуени, котора доилас олоо усеа в ралин адаа ораотки естественноо ка.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Загрузка модели и токенизатора T5\n",
    "model_name = \"t5-large\"  # Можете использовать t5-base или t5-large для лучшего качества\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Русский текст для суммаризации\n",
    "text = \"\"\"\n",
    "Трансформеры — это архитектура модели глубокого обучения, которая добилась большого успеха в различных задачах обработки естественного языка.\n",
    "Ключевая идея трансформеров заключается в механизме внимания, который позволяет модели фокусироваться на различных частях входных данных при прогнозировании.\n",
    "\"\"\"\n",
    "\n",
    "# Подготовка текста для модели\n",
    "input_text = \"summarize: \" + text  # Префикс \"summarize:\" для суммаризации\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "# Генерация результата\n",
    "outputs = model.generate(inputs[\"input_ids\"], max_length=150, num_beams=4, early_stopping=True)\n",
    "\n",
    "# Декодирование и вывод\n",
    "summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "- Коты — одни из самых популярных домашних животных в мире.\n",
      "- Этот процесс включает \n",
      "обучение модели на больших объемах данных, чтобы она могла делать прогнозы или классифицировать новые данные.\n",
      "- В отличие от собак, коты более самостоятельны и часто проводят время в одиночестве, что делает их идеальными питомцами для людей, которые проводят много времени вне дома.\n",
      "- ИИ активно используется \n",
      "в самых разных сферах, от медицины и финансов до автомобилестроения и развлечений.\n",
      "- Они обладают великолепными охотничьими инстинктами и могут часами играть с игрушками, пытаясь поймать невидимых \"жертв\".\n",
      "- В дикой природе коты — отличные охотники, и они могут ловить мелких животных, таких как мыши и птицы.\n",
      "- Глубокое обучение, в свою очередь, \n",
      "является более сложной формой машинного обучения, которая использует многослойные нейронные сети для обработки больших объемов данных и извлечения \n",
      "сложных зависимостей и паттернов.\n",
      "- \n",
      "Искусственный интеллект (ИИ) — это область информатики, которая занимается созданием машин и программ, способных выполнять задачи, \n",
      "которые требуют человеческого интеллекта, такие как восприятие, распознавание образов, принятие решений и обучение.\n",
      "- Машинное обучение — это подраздел ИИ, который позволяет системам учиться на примерах, без явного программирования.\n",
      "- Основные направления ИИ включают машинное обучение, \n",
      "глубокое обучение и нейронные сети, которые позволяют компьютерам \"обучаться\" на основе данных и адаптироваться к новым ситуациям.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "# Убедитесь, что в nltk есть необходимые ресурсы\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Загрузка предобученной модели SBERT для русского языка\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Текст для обработки\n",
    "text = \"\"\"\n",
    "Искусственный интеллект (ИИ) — это область информатики, которая занимается созданием машин и программ, способных выполнять задачи, \n",
    "которые требуют человеческого интеллекта, такие как восприятие, распознавание образов, принятие решений и обучение. ИИ активно используется \n",
    "в самых разных сферах, от медицины и финансов до автомобилестроения и развлечений. Основные направления ИИ включают машинное обучение, \n",
    "глубокое обучение и нейронные сети, которые позволяют компьютерам \"обучаться\" на основе данных и адаптироваться к новым ситуациям.\n",
    "\n",
    "Машинное обучение — это подраздел ИИ, который позволяет системам учиться на примерах, без явного программирования. Этот процесс включает \n",
    "обучение модели на больших объемах данных, чтобы она могла делать прогнозы или классифицировать новые данные. Глубокое обучение, в свою очередь, \n",
    "является более сложной формой машинного обучения, которая использует многослойные нейронные сети для обработки больших объемов данных и извлечения \n",
    "сложных зависимостей и паттернов.\n",
    "\n",
    "Коты — одни из самых популярных домашних животных в мире. Их любят за независимость, игривость и красивое поведение. В отличие от собак, коты более самостоятельны и часто проводят время в одиночестве, что делает их идеальными питомцами для людей, которые проводят много времени вне дома. Они обладают великолепными охотничьими инстинктами и могут часами играть с игрушками, пытаясь поймать невидимых \"жертв\". В дикой природе коты — отличные охотники, и они могут ловить мелких животных, таких как мыши и птицы.\n",
    "\"\"\"\n",
    "\n",
    "# Разбиение текста на предложения с помощью nltk\n",
    "sentences = nltk.sent_tokenize(text, language='russian')\n",
    "\n",
    "# Получение эмбеддингов для каждого предложения\n",
    "sentence_embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "# Для выделения ключевых предложений считаем схожесть между всеми предложениями\n",
    "cosine_scores = util.pytorch_cos_sim(sentence_embeddings, sentence_embeddings)\n",
    "\n",
    "# Теперь для каждого предложения вычислим его общую важность, суммируя все его схожести с другими предложениями\n",
    "importance_scores = cosine_scores.sum(dim=1)\n",
    "\n",
    "# Используем минимальное значение между top_n и длиной списка предложений\n",
    "top_n = min(10, len(sentences))  # количество ключевых предложений\n",
    "top_n_idx = np.argsort(importance_scores.cpu().numpy())[-top_n:]  # Индексы самых важных предложений\n",
    "summary = [sentences[i] for i in top_n_idx]\n",
    "\n",
    "# Вывод суммаризации\n",
    "print(\"Summary:\")\n",
    "for sentence in summary:\n",
    "    print(f\"- {sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: dog\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Загрузка модели и токенизатора T5\n",
    "model_name = \"t5-large\"  # Можете использовать t5-base или t5-large для лучшего качества\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Русский текст для суммаризации\n",
    "text = \"\"\"\n",
    "But i have never eaten dog. I ate cat. \n",
    "\"\"\"\n",
    "\n",
    "# Пример вопроса\n",
    "question = \"what i have never eaten?\"\n",
    "\n",
    "# Подготовка текста для модели\n",
    "input_text = f\"question: {question} context: {text}\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "# Генерация результата\n",
    "outputs = model.generate(inputs[\"input_ids\"], max_length=150, num_beams=4, early_stopping=True)\n",
    "\n",
    "# Декодирование и вывод\n",
    "summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ДЛЯ T5\n",
    "\n",
    "1. Перевод (translate):\n",
    "Для перевода текста с одного языка на другой.\n",
    "\n",
    "Пример:\n",
    "\n",
    "python\n",
    "Копировать код\n",
    "input_text = \"translate English to French: How are you?\"\n",
    "Это запросит модель перевести текст \"How are you?\" с английского на французский.\n",
    "\n",
    "Также можно переводить с русского на другие языки:\n",
    "\n",
    "\n",
    "2. Ответ на вопрос (question):\n",
    "Для задачи ответа на вопросы, задаваемые на основе контекста.\n",
    "\n",
    "\n",
    "3. Классификация (classify):\n",
    "Модели, подобные T5, можно адаптировать для классификации текста, например, для анализа тональности (положительное/отрицательное мнение).\n",
    "\n",
    "4. Преобразование текста (Text Generation) (generate):\n",
    "Для генерации текста, завершения предложения или создания нового контента.\n",
    "\n",
    "\n",
    "5. Заполнение пропусков (fill-mask):\n",
    "Для заполнения пропусков в предложениях. Это полезно для таких задач, как автозаполнение, где нужно предсказать недостающие слова.\n",
    "\n",
    "\n",
    "6. Перефразирование (paraphrase):\n",
    "Модели T5 могут быть использованы для перефразирования предложений, сохраняя их смысл, но меняя форму.\n",
    "\n",
    "\n",
    "7. Чтение текста (summarize):\n",
    "Это задача суммаризации текста, как мы обсуждали ранее.\n",
    "\n",
    "\n",
    "\n",
    "8. Кодирование/Декодирование (encode/decode):\n",
    "Модели T5 могут быть использованы для различных задач, связанных с кодированием и декодированием информации."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
