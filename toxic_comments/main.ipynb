{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast as BertTokenizer, DistilBertModel, AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "pl.seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = 'data/train.csv'\n",
    "TEST = 'data/test.csv'\n",
    "TEST_LABEL = 'data/test_labels.csv'\n",
    "SAMPLE = 'data/sample_submission.csv'\n",
    "EPOCHS = 2\n",
    "MAX_TOKEN_COUNT = 128\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 160it [00:01, 83.66it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([chunk for chunk in tqdm(pd.read_csv(TRAIN, chunksize=1000), desc='Loading data')])\n",
    "test_df = pd.read_csv(TEST)\n",
    "test_label = pd.read_csv(TEST_LABEL)\n",
    "sample_sub = pd.read_csv(SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805  \n",
       "std         0.216627       0.093420  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preparing for fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COLUMNS = df.columns.tolist()[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_toxic = train_df[train_df[LABEL_COLUMNS].sum(axis=1) > 0]\n",
    "train_clean = train_df[train_df[LABEL_COLUMNS].sum(axis=1) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicCommentsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pass pandas dataframe, and tokeizer along with the max token length[128 default]\n",
    "    \n",
    "    Example: \n",
    "    -------\n",
    "    train_dataset = ToxicCommentsDataset(\n",
    "      train_df,\n",
    "      tokenizer,\n",
    "      max_token_len=MAX_TOKEN_COUNT\n",
    "    )\n",
    "\n",
    "    sample_item = train_dataset[0]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        tokenizer: BertTokenizer,\n",
    "        max_token_len: int = 128,\n",
    "        test= False\n",
    "    ):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "        self.test = test\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "        _id = data_row['id']\n",
    "        comment_text = data_row.comment_text\n",
    "        \n",
    "        if not self.test:\n",
    "            labels = data_row[LABEL_COLUMNS]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            comment_text,\n",
    "            max_length=self.max_token_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            add_special_tokens=True, # [CLS] & [SEP]\n",
    "            return_token_type_ids=False,\n",
    "            return_attention_mask=True, #attention_mask\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        if not self.test:\n",
    "            return dict(\n",
    "            _id = _id,\n",
    "            comment_text=comment_text,\n",
    "            input_ids = encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "            labels=torch.FloatTensor(labels)\n",
    "        )\n",
    "        else:\n",
    "            return dict(\n",
    "                _id = _id,\n",
    "                comment_text=comment_text,\n",
    "                input_ids = encoding[\"input_ids\"].flatten(),\n",
    "                attention_mask=encoding[\"attention_mask\"].flatten()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "BERT_MODEL_NAME = 'distilbert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test=False\n",
    "train_dataset = ToxicCommentsDataset(\n",
    "  train_df,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")\n",
    "\n",
    "val_dataset = ToxicCommentsDataset(\n",
    "  val_df,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ToxicCommentsDataset(\n",
    "  test_df,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_TOKEN_COUNT,\n",
    "  test=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicCommentTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):\n",
    "        super().__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)  # загрузка предобученной модели BERT\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)  # добавление линейного слоя\n",
    "        self.n_training_steps = n_training_steps\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        \n",
    "        # Замораживаем все параметры BERT\n",
    "        for param in list(self.bert.parameters())[:-2]:\n",
    "            param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output.last_hidden_state[:, 0, :]\n",
    "        output = self.classifier(hidden_state)\n",
    "        output = torch.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ToxicCommentTagger(len(LABEL_COLUMNS)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BertModel.from_pretrained('bert-base-cased', return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch=len(train_df) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_training_steps = steps_per_epoch * EPOCHS\n",
    "warmup_steps = total_training_steps // 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "  model.train()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  avg_loss = 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "#     batch = [r.to(device) for r in batch]\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)     \n",
    "\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "    outputs = model(input_ids, attention_mask)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    outputs=outputs.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(outputs)\n",
    "\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  print(f\"{step}: {avg_loss}\")\n",
    "  \n",
    "\n",
    "    \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  #returns the loss and predictions\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "  print(\"\\nEvaluating...\")\n",
    "  #t0 = time.time()\n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "  total_labels = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "    # Progress update every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      \n",
    "      # Calculate elapsed time in minutes.\n",
    "      #elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "      # Report progress.\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "\n",
    "#     batch = [r.to(device) for r in batch]\n",
    "    \n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)   \n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      outputs = model(input_ids, attention_mask)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "\n",
    "      outputs = outputs.detach().cpu().numpy()\n",
    "      labels = labels.detach().cpu().numpy()\n",
    "      total_preds.append(outputs)\n",
    "      total_labels.append(labels)\n",
    "\n",
    "\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader)\n",
    "  print(f\"{step}: {avg_loss}\")\n",
    "\n",
    "\n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "  total_labels = np.concatenate(total_labels, axis=0)\n",
    "  true = np.array(total_labels)\n",
    "  pred = np.array(total_preds>0.5)\n",
    "  #print(true)\n",
    "  #print(pred)\n",
    "  for i, name in enumerate(LABEL_COLUMNS):\n",
    "      try:\n",
    "          print(f\"{name} roc_auc {roc_auc_score(true[:, i], pred[:, i])}\")\n",
    "      except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "  print(f\"Evaluate loss {total_loss / len(val_dataloader)}\")\n",
    "  return avg_loss, total_preds, total_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[242], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, EPOCHS))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#train model\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m train_loss, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#evaluate model\u001b[39;00m\n\u001b[0;32m     17\u001b[0m valid_loss, _, _ \u001b[38;5;241m=\u001b[39m evaluate()\n",
      "Cell \u001b[1;32mIn[240], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# add on to the total loss\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m+\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# backward pass to calculate the gradients\u001b[39;00m\n\u001b[0;32m     33\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "EPOCHS = 2\n",
    "#for each epoch\n",
    "for epoch in range(EPOCHS):\n",
    "    clear_output()\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, EPOCHS))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "\n",
    "def evaluate_roc(probs, y_true):\n",
    "    \"\"\"\n",
    "    - Print AUC and accuracy on the test set\n",
    "    - Plot ROC\n",
    "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
    "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
    "    \"\"\"\n",
    "    preds = probs#[:, 1]\n",
    "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f'AUC: {roc_auc:.4f}')\n",
    "       \n",
    "    # Get accuracy over the test set\n",
    "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "    \n",
    "    # Plot ROC AUC\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    }
   ],
   "source": [
    "avg_loss, total_preds, total_labels = evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(LABEL_COLUMNS):\n",
    "    print(f\"label: {name}\")\n",
    "    evaluate_roc(total_preds[:,i]>0.5, total_labels[:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  \n",
    "  print(\"\\nTesting...\")\n",
    "  #t0 = time.time()\n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "  _ids = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(test_dataloader):\n",
    "    \n",
    "    # Progress update every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      \n",
    "      # Calculate elapsed time in minutes.\n",
    "      #elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "      # Report progress.\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(test_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "\n",
    "#     batch = [r.to(device) for r in batch]\n",
    "    _id = batch[\"_id\"]\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    #labels = batch[\"labels\"].to(device)   \n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      loss, outputs = model(input_ids, attention_mask)\n",
    "\n",
    "      total_loss = total_loss + loss\n",
    "\n",
    "      outputs = outputs#.detach().cpu().numpy()\n",
    "      _ids.append(_id)\n",
    "      total_preds.append(outputs)\n",
    "    \n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(test_dataloader) \n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "#   _ids  = torch.cat(_ids, axis=0)\n",
    "  _ids = np.concatenate(_ids, axis=0)\n",
    "  total_preds  = torch.cat(total_preds, axis=0)\n",
    "  results = dict(id=_ids,\n",
    "      predictions = total_preds\n",
    "      )\n",
    "    \n",
    "\n",
    "  return avg_loss, total_preds, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing...\n",
      "  Batch    50  of  4,787.\n",
      "  Batch   100  of  4,787.\n",
      "  Batch   150  of  4,787.\n",
      "  Batch   200  of  4,787.\n",
      "  Batch   250  of  4,787.\n",
      "  Batch   300  of  4,787.\n",
      "  Batch   350  of  4,787.\n",
      "  Batch   400  of  4,787.\n",
      "  Batch   450  of  4,787.\n",
      "  Batch   500  of  4,787.\n",
      "  Batch   550  of  4,787.\n",
      "  Batch   600  of  4,787.\n",
      "  Batch   650  of  4,787.\n",
      "  Batch   700  of  4,787.\n",
      "  Batch   750  of  4,787.\n",
      "  Batch   800  of  4,787.\n",
      "  Batch   850  of  4,787.\n",
      "  Batch   900  of  4,787.\n",
      "  Batch   950  of  4,787.\n",
      "  Batch 1,000  of  4,787.\n",
      "  Batch 1,050  of  4,787.\n",
      "  Batch 1,100  of  4,787.\n",
      "  Batch 1,150  of  4,787.\n",
      "  Batch 1,200  of  4,787.\n",
      "  Batch 1,250  of  4,787.\n",
      "  Batch 1,300  of  4,787.\n",
      "  Batch 1,350  of  4,787.\n",
      "  Batch 1,400  of  4,787.\n",
      "  Batch 1,450  of  4,787.\n",
      "  Batch 1,500  of  4,787.\n",
      "  Batch 1,550  of  4,787.\n",
      "  Batch 1,600  of  4,787.\n",
      "  Batch 1,650  of  4,787.\n",
      "  Batch 1,700  of  4,787.\n",
      "  Batch 1,750  of  4,787.\n",
      "  Batch 1,800  of  4,787.\n",
      "  Batch 1,850  of  4,787.\n",
      "  Batch 1,900  of  4,787.\n",
      "  Batch 1,950  of  4,787.\n",
      "  Batch 2,000  of  4,787.\n",
      "  Batch 2,050  of  4,787.\n",
      "  Batch 2,100  of  4,787.\n",
      "  Batch 2,150  of  4,787.\n",
      "  Batch 2,200  of  4,787.\n",
      "  Batch 2,250  of  4,787.\n",
      "  Batch 2,300  of  4,787.\n",
      "  Batch 2,350  of  4,787.\n",
      "  Batch 2,400  of  4,787.\n",
      "  Batch 2,450  of  4,787.\n",
      "  Batch 2,500  of  4,787.\n",
      "  Batch 2,550  of  4,787.\n",
      "  Batch 2,600  of  4,787.\n",
      "  Batch 2,650  of  4,787.\n",
      "  Batch 2,700  of  4,787.\n",
      "  Batch 2,750  of  4,787.\n",
      "  Batch 2,800  of  4,787.\n",
      "  Batch 2,850  of  4,787.\n",
      "  Batch 2,900  of  4,787.\n",
      "  Batch 2,950  of  4,787.\n",
      "  Batch 3,000  of  4,787.\n",
      "  Batch 3,050  of  4,787.\n",
      "  Batch 3,100  of  4,787.\n",
      "  Batch 3,150  of  4,787.\n",
      "  Batch 3,200  of  4,787.\n",
      "  Batch 3,250  of  4,787.\n",
      "  Batch 3,300  of  4,787.\n",
      "  Batch 3,350  of  4,787.\n",
      "  Batch 3,400  of  4,787.\n",
      "  Batch 3,450  of  4,787.\n",
      "  Batch 3,500  of  4,787.\n",
      "  Batch 3,550  of  4,787.\n",
      "  Batch 3,600  of  4,787.\n",
      "  Batch 3,650  of  4,787.\n",
      "  Batch 3,700  of  4,787.\n",
      "  Batch 3,750  of  4,787.\n",
      "  Batch 3,800  of  4,787.\n",
      "  Batch 3,850  of  4,787.\n",
      "  Batch 3,900  of  4,787.\n",
      "  Batch 3,950  of  4,787.\n",
      "  Batch 4,000  of  4,787.\n",
      "  Batch 4,050  of  4,787.\n",
      "  Batch 4,100  of  4,787.\n",
      "  Batch 4,150  of  4,787.\n",
      "  Batch 4,200  of  4,787.\n",
      "  Batch 4,250  of  4,787.\n",
      "  Batch 4,300  of  4,787.\n",
      "  Batch 4,350  of  4,787.\n",
      "  Batch 4,400  of  4,787.\n",
      "  Batch 4,450  of  4,787.\n",
      "  Batch 4,500  of  4,787.\n",
      "  Batch 4,550  of  4,787.\n",
      "  Batch 4,600  of  4,787.\n",
      "  Batch 4,650  of  4,787.\n",
      "  Batch 4,700  of  4,787.\n",
      "  Batch 4,750  of  4,787.\n"
     ]
    }
   ],
   "source": [
    "avg_test_loss, total_test_preds, sub = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id\n",
       "0       00001cee341fdb12\n",
       "1       0000247867823ef7\n",
       "2       00013b17ad220c46\n",
       "3       00017563c3f7919a\n",
       "4       00017695ad8997eb\n",
       "...                  ...\n",
       "153159  fffcd0960ee309b5\n",
       "153160  fffd7a9a6eb32c16\n",
       "153161  fffda9e8d6fafa9e\n",
       "153162  fffe8f1340a79fc2\n",
       "153163  ffffce3fb183ee80\n",
       "\n",
       "[153164 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = pd.DataFrame()\n",
    "D['id'] = sub['id']\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.128612</td>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.067607</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>0.063421</td>\n",
       "      <td>0.010499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.110680</td>\n",
       "      <td>0.008964</td>\n",
       "      <td>0.056102</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>0.051716</td>\n",
       "      <td>0.006291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.075834</td>\n",
       "      <td>0.008488</td>\n",
       "      <td>0.047074</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.038748</td>\n",
       "      <td>0.007518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.076939</td>\n",
       "      <td>0.009133</td>\n",
       "      <td>0.042555</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.040030</td>\n",
       "      <td>0.007725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.128485</td>\n",
       "      <td>0.009641</td>\n",
       "      <td>0.061437</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>0.057162</td>\n",
       "      <td>0.007573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>0.132118</td>\n",
       "      <td>0.011122</td>\n",
       "      <td>0.065090</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.061263</td>\n",
       "      <td>0.008110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>0.097062</td>\n",
       "      <td>0.009049</td>\n",
       "      <td>0.056917</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>0.048058</td>\n",
       "      <td>0.008485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>0.066616</td>\n",
       "      <td>0.009444</td>\n",
       "      <td>0.039752</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.032639</td>\n",
       "      <td>0.007370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>0.067158</td>\n",
       "      <td>0.009054</td>\n",
       "      <td>0.040448</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.033224</td>\n",
       "      <td>0.007178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>0.090863</td>\n",
       "      <td>0.008361</td>\n",
       "      <td>0.043346</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>0.037446</td>\n",
       "      <td>0.005723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     toxic  severe_toxic   obscene    threat  \\\n",
       "0       00001cee341fdb12  0.128612      0.013350  0.067607  0.003506   \n",
       "1       0000247867823ef7  0.110680      0.008964  0.056102  0.002153   \n",
       "2       00013b17ad220c46  0.075834      0.008488  0.047074  0.002684   \n",
       "3       00017563c3f7919a  0.076939      0.009133  0.042555  0.002428   \n",
       "4       00017695ad8997eb  0.128485      0.009641  0.061437  0.002487   \n",
       "...                  ...       ...           ...       ...       ...   \n",
       "153159  fffcd0960ee309b5  0.132118      0.011122  0.065090  0.002526   \n",
       "153160  fffd7a9a6eb32c16  0.097062      0.009049  0.056917  0.003017   \n",
       "153161  fffda9e8d6fafa9e  0.066616      0.009444  0.039752  0.002844   \n",
       "153162  fffe8f1340a79fc2  0.067158      0.009054  0.040448  0.002951   \n",
       "153163  ffffce3fb183ee80  0.090863      0.008361  0.043346  0.002220   \n",
       "\n",
       "          insult  identity_hate  \n",
       "0       0.063421       0.010499  \n",
       "1       0.051716       0.006291  \n",
       "2       0.038748       0.007518  \n",
       "3       0.040030       0.007725  \n",
       "4       0.057162       0.007573  \n",
       "...          ...            ...  \n",
       "153159  0.061263       0.008110  \n",
       "153160  0.048058       0.008485  \n",
       "153161  0.032639       0.007370  \n",
       "153162  0.033224       0.007178  \n",
       "153163  0.037446       0.005723  \n",
       "\n",
       "[153164 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D[LABEL_COLUMNS] = (sub['predictions'].cpu().numpy())\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.to_csv(\"submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
